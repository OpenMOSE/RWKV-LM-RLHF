python train.py --load_model "/workspace/output/phi-4/rwkv-phi4-stage2.pth" \
 --wandb "RWKV-LM-RLHF px070 Phi-4 Stage3" --proj_dir "/workspace/output/phi-4/stage3p0" \
 --vocab_size 100352 --ctx_len 8192 \
 --head_size_a 64 \
 --epoch_steps 1000 --epoch_count 200 --epoch_begin 0 --epoch_save 1 \
 --micro_bsz 4 --n_layer 40 --n_embd 5120 --dim_ffn 17920 \
 --warmup_steps 100 --beta1 0.9 --beta2 0.999 --adam_eps 1e-8 \
 --accelerator gpu --devices 1 --precision 'bf16' \
 --grad_cp 1 --my_testing "pxa070" \
 --strategy deepspeed_stage_2_offload \
 --layer_profile 'layerprofile/40_TEST_full.csv' \
 --fla 0 \
 --infctx 0 \
 --state 0 \
 --quant 0 \
 --quant_mode 'int8'\
 --gpu_arch 'triton' \
 --limited_lora 0 \
 --sft 1 \
 --sft_jsonmode 1 \
 --sft_jsonmode_tokenizermode 'phi-4' \
 --smoothing 0.001 \
 --random_mode 1 \
 --infctx_dataset_multiplier 8 \
 --optim '' \
 --train_data_file '/workspace/r2' \
 --accumulate_grad_batches 1
